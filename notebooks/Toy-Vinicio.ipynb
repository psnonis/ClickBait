{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "In this question, we consider an application of SVM as a classifier. The SVM classifier main idea is to separate the two classess (We will transform the data from $y_i \\in \\{0, 1\\}$ to $y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "## Let's start with $\\ell_2$ SVM\n",
    "\n",
    "The ridged-SVM classification problem can be formulated as the following optimization problem:\n",
    "\n",
    "$$\\underset{w, b}{\\text{min }} \\frac{\\lambda}{2}\\left\\|w\\right\\|_2^2 + \\frac{1}{n}\\sum_{i=1}^{N}{\\left(1 - y_i\\left(w^\\top x_i +b\\right)\\right)_+}$$\n",
    "\n",
    "where $y_i$ denotes the $i^{th}$ label, $x_i$ denotes the $i^{th}$ vector of features in the dataset, $w$ is the weights or vector of coefficients, $b$ is the bias term, and $\\lambda$ is a model parameter is inversely related to the ridge regularization of the weights vector $w$. This is a quadratic optimization problem.\n",
    "\n",
    "For this SVM, we are using a Linear Kernel, that explain the hyperplane that we are using on the Loss Function. Later we will play with this idea and introduce more interesting kernels, and introduce some non-linearities.\n",
    "\n",
    "<!-- Using `cvxpy`, implement this SVM (estimate the $w$ and $b$ parameters) on the training set and tune the parameter $C$ from $0$ to $100$ by checking classification accuracy on the validation set. Plot the training accuracy versus $C$ curve and validation accuracy versus $C$ curve. Briefly comment on the results. -->\n",
    "\n",
    "### Gradient Descent - Reprise\n",
    "\n",
    "Let's compute the derivatives of the Loss function so we can use Gradient Descent as our method of solving for the weights of SVM. We have two terms on our Loss function, the regularized part and the sum of the errors with the hyperplane\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\omega} \\frac{\\lambda}{2}\\left\\|w\\right\\|_2^2 = \\lambda \\omega\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\omega} {\\left(1 - y_i\\left(w^\\top x_i+b\\right)\\right)_+}  = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            0 & \\quad \\text{if} \\quad y_i\\left(w^\\top x_i+b\\right) \\geq 1 \\\\\n",
    "            -y_ix_i , & \\quad otherwise\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$\n",
    "\n",
    "To understand the process of the gradient, it's divided into 2 parts: the Regularizer and the Hyperplane. When a sample $x_i$ it's correctly classified, we update the vector only by the regularizer, if the sample $x_i$ it's incorrectly misclassified, we update the weights with both the regularizer and the gradient of the plane. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "app_name = \"svm_toy\"\n",
    "master = \"local[*]\"\n",
    "sc = SparkSession.builder\\\n",
    "     .config('spark.executor.memory',       '4G')\\\n",
    "     .config('spark.driver.memory',        '40G')\\\n",
    "     .config('spark.driver.maxResultSize', '10G')\\\n",
    "     .getOrCreate()\n",
    "sc = sc.sparkContext\n",
    "sq = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctr</th>\n",
       "      <th>i01</th>\n",
       "      <th>i02</th>\n",
       "      <th>i03</th>\n",
       "      <th>i04</th>\n",
       "      <th>i05</th>\n",
       "      <th>i06</th>\n",
       "      <th>i07</th>\n",
       "      <th>i08</th>\n",
       "      <th>i09</th>\n",
       "      <th>...</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>s22</th>\n",
       "      <th>s23</th>\n",
       "      <th>s24</th>\n",
       "      <th>s25</th>\n",
       "      <th>s26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27c07bd6</td>\n",
       "      <td>c61e82d7</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>ff3ce4c0</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>d691765a</td>\n",
       "      <td>445bbe3b</td>\n",
       "      <td>d1d45fc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>675.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>c21c3e4c</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>cad88c3b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>60a57787</td>\n",
       "      <td>9b3e8820</td>\n",
       "      <td>17723a96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27c07bd6</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>2efde463</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>a23da47b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>65c55747</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>f868e7eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27c07bd6</td>\n",
       "      <td>c21c3e4c</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>29d21ab1</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>69e4f188</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>bb574173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>07070d63</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>e5195a68</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>9be5c7a4</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>2fede552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ctr  i01  i02    i03   i04     i05    i06    i07   i08     i09  ...  \\\n",
       "78    -1  0.0    1   15.0  16.0  1624.0   24.0    5.0  20.0   391.0  ...   \n",
       "79    -1  0.0    1  675.0  20.0    60.0  659.0    7.0  33.0  2256.0  ...   \n",
       "97    -1  0.0    1    8.0   4.0  1213.0   11.0  596.0  16.0    16.0  ...   \n",
       "133   -1  0.0   -1   58.0  20.0  2728.0  152.0    7.0  15.0   298.0  ...   \n",
       "217    1  6.0   15    1.0   4.0    89.0    4.0   72.0  24.0   125.0  ...   \n",
       "\n",
       "          s17       s18       s19       s20       s21       s22       s23  \\\n",
       "78   27c07bd6  c61e82d7  21ddcdc9  5840adea  ff3ce4c0  c9d4222a  423fab69   \n",
       "79   e5ba7672  c21c3e4c  21ddcdc9  b1252a9d  cad88c3b  ad3062eb  bcdee96c   \n",
       "97   27c07bd6  e88ffc9d  2efde463  a458ea53  a23da47b  ad3062eb  c7dc6720   \n",
       "133  27c07bd6  c21c3e4c  21ddcdc9  b1252a9d  29d21ab1  ad3062eb  bcdee96c   \n",
       "217  3486227d  07070d63  21ddcdc9  5840adea  e5195a68  c9d4222a  32c7478e   \n",
       "\n",
       "          s24       s25       s26  \n",
       "78   d691765a  445bbe3b  d1d45fc5  \n",
       "79   60a57787  9b3e8820  17723a96  \n",
       "97   65c55747  cb079c2d  f868e7eb  \n",
       "133  69e4f188  e8b83407  bb574173  \n",
       "217  9be5c7a4  2bf691b1  2fede552  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the toy dataset. Also, let's replace 0 for -1 in the Label data, so we can use the perceptron\n",
    "toy_data = pd.read_pickle('../data/ToyData.pkl')\n",
    "toy_data['ctr'] = toy_data['ctr'].replace(0,-1)\n",
    "toy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array(['0.0', '1', '15.0', '16.0', '1624.0', '24.0', '5.0', '20.0',\n",
       "         '391.0', '0.0', '3.0', '0.0', '16.0', '05db9164', '333137d9',\n",
       "         '0f8b497f', '8d0c7214', '25c83c98', '7e0ccccf', '7c59aadb',\n",
       "         '0b153874', 'a73ee510', '41c624fe', 'ff78732c', 'a0c32c81',\n",
       "         '9b656adc', '07d13a8f', '6cfa4ac6', '6b98792b', '27c07bd6',\n",
       "         'c61e82d7', '21ddcdc9', '5840adea', 'ff3ce4c0', 'c9d4222a',\n",
       "         '423fab69', 'd691765a', '445bbe3b', 'd1d45fc5'], dtype='<U32'), '-1')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform our toy data set into a RDD, with the corresponding form (y, features_array)\n",
    "# We map to a list to be able to use regular RDD commands. We use a helper function to parse the Dataframe\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Map records from Row --> (tuple,of,fields)\n",
    "    \"\"\"\n",
    "    fields = np.array(line) #Will be added later , dtype = 'float')\n",
    "    features,y = fields[1:], fields[0]\n",
    "    return(features, y)\n",
    "\n",
    "toy_dataRDD = sq.createDataFrame(toy_data).rdd.map(parse).cache()\n",
    "\n",
    "# Take the first one to chack it's working\n",
    "toy_dataRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part c - gradient descent with regularization\n",
    "def SVM_GDupdate(dataRDD, W, lr = 0.1, regPar = 0.1, reg = 'l2', kernel = 'linear'):\n",
    "    \"\"\"\n",
    "    Perform one gradient descent update, you can decide kernel or Type of regularization #Work in Progress\n",
    "    Args:\n",
    "        dataRDD  - tuple of (features_array, y)\n",
    "        W        - (array) model coefficients with bias at index 0\n",
    "        lr       - (float) defaults to 0.1\n",
    "        regPar   - (float) defaults to 0.1\n",
    "        reg      - (str) Type of regularization used - defaults to L2, can go to L1\n",
    "        kernel   - (str) type of kernel used, defaults to Linear\n",
    "    Returns:\n",
    "        model   - (array) updated coefficients, bias still at index 0\n",
    "    \"\"\"\n",
    "    # First step, we broadcast the initial weights\n",
    "    w = sq.broadcast(W)\n",
    "    \n",
    "    # Second, let's augment our data\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    \n",
    "    # Helper functions\n",
    "    def l2_grad(line):\n",
    "        \"\"\"\n",
    "        Helper function with the L2 gradient\n",
    "        Args:\n",
    "            w     - Array of old weights to be updated\n",
    "            line  - Observation point tuple (feature_array, Y)\n",
    "        Output:\n",
    "            w_new - New weights\n",
    "        \"\"\"\n",
    "        # From the tuple of observations, get the y and X\n",
    "        y, X = line[1], line[0]\n",
    "        \n",
    "        # The gradient will depend on the misclassification of any given point\n",
    "        if (y*np.dot(X,w.value)) < 1:\n",
    "            grad =  -1*y*x\n",
    "        else:\n",
    "            grad = 0\n",
    "            \n",
    "        # Finally we yield the new total gradient\n",
    "        yield grad\n",
    "                \n",
    "    # Let's add to each gradient its penalization, depending of the type of regression       \n",
    "    if reg == 'l2':\n",
    "        # Calculate the batch gradient\n",
    "        grad = dataRDD.map(l2_grad).mean()\n",
    "        # We only regularized features weights\n",
    "        w_nobias = np.append([0.0], W[1:])\n",
    "        # We update the gradient including regularization\n",
    "        grad += regPar*w_nobias\n",
    "       \n",
    "    # Update the Weights\n",
    "    new_model = W-lr*grad\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
