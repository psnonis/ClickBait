{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from code.common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Spark Initializing\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Spark Initializing in 6.184 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initSpark(workingSet, application = 'prep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Criteo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Data Loading at /home/jovyan/work/notebooks/data\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Data Loading in 64.787 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loadData(workingSet, data = 'data', clean = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training, Test, and Dev Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Data Splitting at [0.8, 0.1, 0.1]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Data Splitting in 125.804 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "splitData(workingSet, ratios = [.8,.1,.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering : Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.engineering import catFillUndefined, catFindFrequent, catMaskUncommon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Undefined Values with Special Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Categorical Fill Undefined Terms on train\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Categorical Fill Undefined Terms in 39.873 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Categorical Fill Undefined Terms on test\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Categorical Fill Undefined Terms in 7.521 Seconds\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Categorical Fill Undefined Terms on dev\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Categorical Fill Undefined Terms in 7.590 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "catFillUndefined(workingSet, subset = 'train', term = 'deadbeef')\n",
    "catFillUndefined(workingSet, subset = 'test',  term = 'deadbeef')\n",
    "catFillUndefined(workingSet, subset = 'dev',   term = 'deadbeef')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Uncommon Values for Each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Categorical Find Frequent Terms on train\n",
      "--------------------------------------------------------------------------------\n",
      "s01 found     1451 uncommon categories of     1460 distinct categories ->   9 frequent categories = ['05db9164', '68fd1e64', '5a9ed9b0', '8cf07265', 'be589b51', '5bfa8ab5', '87552397', 'f473b8dc', '39af2607']\n",
      "s02 found      562 uncommon categories of      581 distinct categories ->  19 frequent categories = ['38a947a1', '207b2d81', '38d50e09', '1cfdf714', '287130e0', '4f25e98b', '09e68b86', '421b43cd', '58e67aaf', '80e26c9b', '89ddfee8', '08d6d899', '2c16a946', '95e2d337', '04e09220', 'f0cf0024', 'a796837e', '0468d672', 'e112a9de']\n",
      "s03 found  8382435 uncommon categories of  8382439 distinct categories ->   4 frequent categories = ['deadbeef', 'd032c263', '02cf9876', 'aa8c1539']\n",
      "s04 found  1885229 uncommon categories of  1885236 distinct categories ->   7 frequent categories = ['c18be181', 'deadbeef', '29998ed1', 'd16679b9', '85dd697c', '13508380', 'f922efad']\n",
      "s05 found      299 uncommon categories of      305 distinct categories ->   6 frequent categories = ['25c83c98', '4cf72387', '43b19349', '384874ce', '30903e74', '0942e0a7']\n",
      "s06 found       17 uncommon categories of       24 distinct categories ->   7 frequent categories = ['7e0ccccf', 'fbad5c96', 'fe6b92e5', 'deadbeef', '13718bbd', '6f6d9be8', '3bf701e7']\n",
      "s07 found    12488 uncommon categories of    12490 distinct categories ->   2 frequent categories = ['1c86e0eb', 'dc7659bd']\n",
      "s08 found      626 uncommon categories of      633 distinct categories ->   7 frequent categories = ['0b153874', '5b392875', '1f89b562', '37e4aa92', '062b5529', '51d76abe', 'c8ddd494']\n",
      "s09 found        1 uncommon categories of        3 distinct categories ->   2 frequent categories = ['a73ee510', '7cc72ec2']\n",
      "s10 found    89026 uncommon categories of    89028 distinct categories ->   2 frequent categories = ['3b08e48b', 'efea433b']\n",
      "s11 found     5646 uncommon categories of     5651 distinct categories ->   5 frequent categories = ['755e4a50', 'e51ddf94', '7f8ffe57', '4d8549da', '8b94178b']\n",
      "s12 found  6953560 uncommon categories of  6953565 distinct categories ->   5 frequent categories = ['deadbeef', 'dfbb09fb', '6aaba33c', '8fe001f4', 'd8c29807']\n",
      "s13 found     3187 uncommon categories of     3194 distinct categories ->   7 frequent categories = ['5978055e', '3516f6e6', '46f42a63', '025225f2', '1aa94af3', '51b97b8f', '740c210d']\n",
      "s14 found       19 uncommon categories of       27 distinct categories ->   8 frequent categories = ['b28479f6', '07d13a8f', '1adce6ef', '64c94865', 'cfef1c29', '051219e6', '8ceecbc8', 'f862f261']\n",
      "s15 found    14754 uncommon categories of    14756 distinct categories ->   2 frequent categories = ['2d0bb053', 'd345b1a0']\n",
      "s16 found  4591539 uncommon categories of  4591544 distinct categories ->   5 frequent categories = ['deadbeef', '84898b2a', 'b041b04a', '36103458', 'c64d548f']\n",
      "s17 found        1 uncommon categories of       10 distinct categories ->   9 frequent categories = ['e5ba7672', '07c540c4', 'd4bb7bd8', '3486227d', '776ce399', '27c07bd6', '8efede7f', '1e88c74f', '2005abd1']\n",
      "s18 found     5569 uncommon categories of     5580 distinct categories ->  11 frequent categories = ['e88ffc9d', '891589e7', '2804effd', 'c21c3e4c', '5aed7436', '7ef5affa', '5bb2ec8e', '395856b0', '582152eb', '7b06fafe', '005c6740']\n",
      "s19 found     2163 uncommon categories of     2166 distinct categories ->   3 frequent categories = ['deadbeef', '21ddcdc9', '55dd3565']\n",
      "s20 found        0 uncommon categories of        4 distinct categories ->   4 frequent categories = ['deadbeef', 'b1252a9d', '5840adea', 'a458ea53']\n",
      "s21 found  5895435 uncommon categories of  5895440 distinct categories ->   5 frequent categories = ['deadbeef', '0014c32a', '723b4dfd', 'e587c466', '5f957280']\n",
      "s22 found       15 uncommon categories of       18 distinct categories ->   3 frequent categories = ['deadbeef', 'ad3062eb', 'c9d4222a']\n",
      "s23 found        7 uncommon categories of       15 distinct categories ->   8 frequent categories = ['32c7478e', '3a171ecb', '423fab69', 'bcdee96c', 'be7c41b4', 'c7dc6720', '55dd3565', 'dbb486d7']\n",
      "s24 found   258804 uncommon categories of   258817 distinct categories ->  13 frequent categories = ['3fdb382b', 'b34f3128', '3b183c5c', '1793a828', 'deadbeef', '45ab94c8', 'aee52b6f', '9117a34a', 'ded4aac9', '8fc66e78', 'b258af68', 'df487a73', 'd9556584']\n",
      "s25 found       94 uncommon categories of      104 distinct categories ->  10 frequent categories = ['deadbeef', '001f3601', 'e8b83407', 'ea9a246c', 'cb079c2d', '9b3e8820', '445bbe3b', '2bf691b1', 'f0f449dd', '010f6491']\n",
      "s26 found   133362 uncommon categories of   133369 distinct categories ->   7 frequent categories = ['deadbeef', '49d68486', 'c84c4aec', '2fede552', 'c27f155b', 'aa5f0a15', '984e0db0']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Finished Categorical Find Frequent Terms in 157.710 Seconds\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "catFindFrequent(workingSet, subset = 'train', threshold = 360000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Uncommon Values with Special Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Starting Categorical Mask Uncommon Terms on train\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "catMaskUncommon(workingSet, subset = 'train', term = 'rarebeef')\n",
    "catMaskUncommon(workingSet, subset = 'test',  term = 'rarebeef')\n",
    "catMaskUncommon(workingSet, subset = 'dev',   term = 'rarebeef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catFindFrequent(workingSet, subset = 'train', threshold = 360000, remember = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at a few columns to confirm it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare.groupby('s02').count().sort('count', ascending = False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare.groupby(\"s03\").count().sort('count', ascending = False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare.groupby(\"s23\").count().sort('count', ascending = False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the columns\n",
    "encoder = OneHotEncoderEstimator(inputCols= cat_features , outputCols=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoder.fit(df_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages   = [StringIndexer(inputCol = f, outputCol= f'{f}_index') for f in cat_features]\n",
    "pipeline = Pipeline(stages = stages)\n",
    "model    = pipeline.fit(df_rare)\n",
    "df_indexed       = model.transform(df_rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed = df_indexed.drop(*[col for col in df_indexed.columns if 'i' not in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = [f'{feature}_encoded' for feature in cat_features ]\n",
    "\n",
    "# Encode the columns\n",
    "encoder = OneHotEncoderEstimator(inputCols= cat_features , outputCols=encoded_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare = df_filled.replace(rb_values['s03'], 'rarebeef', 's03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_rare.take(10), columns = df_rare.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rare.groupBy('s01').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_rare = df_filled.replace(rb_values['s03'], 'rarebeef', 's03')\n",
    "df_rare.groupBy('s03').count().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if  not exists('../data/train.parquet.indexed'):\n",
    "\n",
    "    stages   = [StringIndexer(inputCol = f, outputCol= f'{f}_index').setHandleInvalid('keep') for f in cat_columns]\n",
    "    pipeline = Pipeline(stages = stages)\n",
    "    model    = pipeline.fit(df)\n",
    "    df       = model.transform(df)\n",
    "\n",
    "    \"\"\"\n",
    "    for c in cat_indexes:\n",
    "        df = df.withColumn(c, col(c).cast('float'))\n",
    "    \n",
    "    df = df.select(['ctr'] + num_columns + cat_indexes)\n",
    "    \"\"\"\n",
    "    df.write.parquet('../data/train.parquet.indexed')\n",
    "    \n",
    "df = ss.read.parquet('../data/train.parquet.indexed')\n",
    "tf = df.sample(fraction = 0.01, seed = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [f'{f}_index' for f in cat_features]:\n",
    "    df = df.withColumn(c, col(c).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('../data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ss.read.parquet('../data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distinct = {}\n",
    "\n",
    "for f in cat_features:\n",
    "    s  = ti.time()\n",
    "    cat_distinct[f] = df.agg(countDistinct(f)).collect()[0][0]\n",
    "    print( f'{f} : {cat_distinct[f]:>8} : {ti.time() - s:.3f}' )\n",
    "\n",
    "print( f'sum : {sum(cat_distinct.values()):>8}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distinct = {}\n",
    "\n",
    "for f in cat_features:\n",
    "    s  = ti.time()\n",
    "    cat_distinct[f] = df.agg(countDistinct(f)).collect()[0][0]\n",
    "    print( f'{f} : {cat_distinct[f]:>8} : {ti.time() - s:.3f}' )\n",
    "\n",
    "print( f'sum : {sum(cat_distinct.values()):>8}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imputer = Imputer(inputCols = num_features, outputCols = num_features)\n",
    "model   = imputer.fit(df)\n",
    "xf      = model.transform(df)\n",
    "xf.describe(num_features).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_assembler = VectorAssembler(inputCols = num_features, outputCol = 'num_features')\n",
    "cat_assembler = VectorAssembler(inputCols = cat_features, outputCol = 'cat_features')\n",
    "xf            = num_assembler.transform(xf)\n",
    "#xf            = cat_assembler.transform(xf)\n",
    "\n",
    "xf.describe(num_features).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
