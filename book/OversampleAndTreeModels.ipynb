{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "from code.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill -9 java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SQLContext\n",
    "#sc = SparkContext.getOrCreate()\n",
    "#sqlContext = SQLContext(sc)\n",
    "ss = SparkSession.builder\\\n",
    "     .config('spark.executor.memory',       '4G')\\\n",
    "     .config('spark.driver.memory',        '40G')\\\n",
    "     .config('spark.driver.maxResultSize', '10G')\\\n",
    "     .getOrCreate()\n",
    "sc = ss.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.parquet.normed.masked-060000.encode.picked-000987.packed-001000.oversampled\n",
      "tests.parquet.normed.masked-060000.encode.picked-000987.packed-001000\n",
      "train.parquet.normed.masked-060000.encode.picked-000987.packed-001000\n",
      "valid.parquet.normed.masked-060000.encode.picked-000987.packed-001000\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if 'parquet.normed.masked-060000.encode.picked-000987.packed' in file:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.parquet.normed.masked-060000.encode.picked-000987.packed-001000.oversampled'\n",
    "dev_file = 'data/valid.parquet.normed.masked-060000.encode.picked-000987.packed-001000'\n",
    "test_file = 'data/tests.parquet.normed.masked-060000.encode.picked-000987.packed-001000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sqlContext.read.parquet(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the distribution across the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9394612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27274974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label     count\n",
       "0      1   9394612\n",
       "1      0  27274974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts_df = train.groupby('label').count().toPandas()\n",
    "label_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_count = label_counts_df.at[0, 'count']\n",
    "positive_count = label_counts_df.at[1, 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train examples is 36669586\n",
      "Percentage of negative examples is 25.619629302605162\n",
      "Percentage of postive examples is 74.38037069739484\n"
     ]
    }
   ],
   "source": [
    "total_count = positive_count + negative_count\n",
    "print(f'Total number of train examples is {total_count}')\n",
    "print (f'Percentage of negative examples is {negative_count*100/total_count}')\n",
    "print (f'Percentage of postive examples is {positive_count*100/total_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_positives = train.filter(train['label']==1).sample(withReplacement=True, fraction=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+\n",
      "|label|            features|            weight|\n",
      "+-----+--------------------+------------------+\n",
      "|    1|(1000,[0,1,2,4,5,...|0.7438037069739484|\n",
      "|    1|(1000,[0,1,2,4,5,...|0.7438037069739484|\n",
      "|    1|(1000,[0,1,2,4,5,...|0.7438037069739484|\n",
      "|    1|(1000,[0,1,2,4,5,...|0.7438037069739484|\n",
      "|    1|(1000,[0,1,2,4,5,...|0.7438037069739484|\n",
      "+-----+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extra_positives.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the extra positive examples and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_train = train.union(extra_positives)\n",
    "oversampled_train = oversampled_train.sample(withReplacement = False, fraction = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_train.write.parquet('data/train.parquet.normed.masked-060000.encode.picked-000987.packed.oversampled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/train.parquet.normed.masked-060000.encode.picked-000987.packed-001000.oversampled'\n",
    "dev_file = 'data/valid.parquet.normed.masked-060000.encode.picked-000987.packed-001000'\n",
    "test_file = 'data/tests.parquet.normed.masked-060000.encode.picked-000987.packed-001000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sqlContext.read.parquet(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(labelCol=\"label\", featuresCol = \"features\")\n",
    "    \n",
    "print('Starting training')\n",
    "start_train = time()\n",
    "model = estimator.fit(train)\n",
    "end_train = time()\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(estimator, train_file, dev_file, test_file, labelCol=\"label\", featuresCol=\"features\", *args, **kwargs):\n",
    "    \n",
    "    train = sqlContext.read.parquet(train_file)\n",
    "    \n",
    "    algorithm_name = estimator.__name__\n",
    "    \n",
    "    estimator = estimator(labelCol=labelCol, featuresCol = featuresCol, *args, **kwargs)\n",
    "    \n",
    "    print('Starting training')\n",
    "    start_train = time()\n",
    "    model = estimator.fit(train)\n",
    "    end_train = time()\n",
    "    print('Finished training')\n",
    "    \n",
    "    dev = sqlContext.read.parquet(dev_file)\n",
    "    \n",
    "    print('Making predictions')\n",
    "    train_predictions = model.transform(train)\n",
    "    dev_predictions = model.transform(dev)\n",
    "    test_predictions = model.transform(test)\n",
    "    end_predictions = time()\n",
    "    print('Compeleted making predictions')\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "    # Calculate the AUC for train and dev\n",
    "    auc_train = evaluator.evaluate(train_predictions)\n",
    "    auc_dev = evaluator.evaluate(test_predictions)\n",
    "    auc_test = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    print(f'{algorithm_name} - AUC on train is: {auc_train * 100:.2f}')\n",
    "    print(f'{algorithm_name} - AUC on dev is: {auc_dev * 100:.2f}')\n",
    "    print(f'{algorithm_name} - AUC on dev is: {auc_test * 100:.2f}')\n",
    "    print(f'Time to train is {(end_train-start_train):.2f} seconds')\n",
    "    print(f'Time to predict is {(end_predictions-end_train):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Finished training\n",
      "Making predictions\n",
      "Compeleted making predictions\n",
      "DecisionTreeClassifier - AUC on train is: 57.15\n",
      "DecisionTreeClassifier - AUC on dev is: 57.14\n",
      "Time to train is 4.57 minutes\n",
      "Time to predict is 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "train_estimator(estimator=DecisionTreeClassifier, train_file=train_file, dev_file=dev_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Finished training\n",
      "Making predictions\n",
      "Compeleted making predictions\n",
      "RandomForestClassifier - AUC on train is: 70.57\n",
      "RandomForestClassifier - AUC on dev is: 70.56\n",
      "Time to train is 6.35 minutes\n",
      "Time to predict is 0.00 minutes\n"
     ]
    }
   ],
   "source": [
    "train_estimator(estimator=RandomForestClassifier, train_file=train_file, dev_file=dev_file, numTrees=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    }
   ],
   "source": [
    "train_estimator(estimator=GBTClassifier, train_file=train_file, dev_file=dev_file, maxIter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runnning this with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(estimator, train_file, dev_file, test_file, labelCol=\"label\", featuresCol=\"features\", *args, **kwargs):\n",
    "    \n",
    "    train = sqlContext.read.parquet(train_file)\n",
    "    \n",
    "    algorithm_name = estimator.__name__\n",
    "    \n",
    "    estimator = estimator(labelCol=labelCol, featuresCol = featuresCol, *args, **kwargs)\n",
    "    \n",
    "    print('Starting training')\n",
    "    start_train = time()\n",
    "    model = estimator.fit(train)\n",
    "    end_train = time()\n",
    "    print('Finished training')\n",
    "    \n",
    "    dev = sqlContext.read.parquet(dev_file)\n",
    "    \n",
    "    test = sqlContext.read.parquet(test_file)\n",
    "    \n",
    "    print('Making predictions')\n",
    "    train_predictions = model.transform(train)\n",
    "    dev_predictions = model.transform(dev)\n",
    "    test_predictions = model.transform(test)\n",
    "    end_predictions = time()\n",
    "    print('Compeleted making predictions')\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "    # Calculate the AUC for train and dev\n",
    "    auc_train = evaluator.evaluate(train_predictions)\n",
    "    auc_dev = evaluator.evaluate(dev_predictions)\n",
    "    auc_test = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    print(f'{algorithm_name} - AUC on train is: {auc_train * 100:.2f}')\n",
    "    print(f'{algorithm_name} - AUC on dev is: {auc_dev * 100:.2f}')\n",
    "    print(f'{algorithm_name} - AUC on test is: {auc_test * 100:.2f}')\n",
    "    print(f'Time to train is {(end_train-start_train):.2f} seconds')\n",
    "    print(f'Time to predict is {(end_predictions-end_train):.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Finished training\n",
      "Making predictions\n",
      "Compeleted making predictions\n",
      "DecisionTreeClassifier - AUC on train is: 53.97\n",
      "DecisionTreeClassifier - AUC on dev is: 53.97\n",
      "DecisionTreeClassifier - AUC on dev is: 53.95\n",
      "Time to train is 270.91 seconds\n",
      "Time to predict is 0.56 seconds\n"
     ]
    }
   ],
   "source": [
    "train_estimator(estimator=DecisionTreeClassifier, train_file=train_file, dev_file=dev_file, test_file=test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    }
   ],
   "source": [
    "train_estimator(estimator=RandomForestClassifier, train_file=train_file, dev_file=dev_file, test_file=test_file, numTrees=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_estimator(estimator=GBTClassifier, train_file=train_file, dev_file=dev_file, test_file, maxIter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
