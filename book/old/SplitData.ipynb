{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import seaborn as sb\n",
    "import time    as ti\n",
    "import itertools\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg         import Vectors\n",
    "from pyspark.ml.feature        import OneHotEncoderEstimator, StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml                import Pipeline\n",
    "\n",
    "from pyspark.sql               import SparkSession, SQLContext\n",
    "from pyspark.sql.types         import StructType, StructField, BooleanType, IntegerType, StringType, DoubleType, BinaryType, FloatType\n",
    "from pyspark.sql.functions     import countDistinct, col, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder\\\n",
    "     .config('spark.executor.memory',       '4G')\\\n",
    "     .config('spark.driver.memory',        '40G')\\\n",
    "     .config('spark.driver.maxResultSize', '10G')\\\n",
    "     .getOrCreate()\n",
    "sc = ss.sparkContext\n",
    "sq = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\n",
    "\n",
    "for f in range(0, 39 + 1):\n",
    "    if   f == 0 : schema.add(StructField(f'ctr',        FloatType(), True))\n",
    "    elif f < 14 : schema.add(StructField(f'i{f   :02}', FloatType(), True))\n",
    "    else        : schema.add(StructField(f's{f-13:02}',  StringType(), True))\n",
    "\n",
    "df = sq.read.format('csv')\\\n",
    "            .options(header = 'true', delimiter = '\\t')\\\n",
    "            .schema(schema)\\\n",
    "            .load('../data/train.txt')\n",
    "\n",
    "num_features = [c for c in df.columns if 'i' in c]\n",
    "cat_features = [c for c in df.columns if 's' in c]\n",
    "\n",
    "tf           = df.sample(fraction = 0.01, seed = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trndf,devdf,tstdf = df.randomSplit([0.8,0.1,0.1],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trndf.write.parquet('../data/train_w261.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "devdf.write.parquet('../data/dev_w261.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstdf.write.parquet('../data/test_w261.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
